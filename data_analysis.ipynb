{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Function to load and concatenate all Excel files from a list\n",
    "def load_and_concatenate_excel_files(file_list):\n",
    "    dataframes = []\n",
    "    for file in file_list:\n",
    "        df = pd.read_excel(file)\n",
    "        # Ensure 'file_name' column exists by adding it\n",
    "        df['file_name'] = file.split('/')[-1]  # Extract the file name from the path\n",
    "        dataframes.append(df)\n",
    "    concatenated_df = pd.concat(dataframes, ignore_index=True)\n",
    "    return concatenated_df\n",
    "\n",
    "# Function to perform average calculation and plotting\n",
    "def calculate_average(grouped_data, x_values):\n",
    "    averages = {}\n",
    "    for year in grouped_data['year'].unique():\n",
    "        year_data = grouped_data[grouped_data['year'] == year]\n",
    "        averages[year] = [(x, year_data[year_data[x_values] == x]['number_of_posts'].sum() / year_data[year_data[x_values] == x]['number_of_active_channels'].sum() if year_data[year_data[x_values] == x]['number_of_active_channels'].sum() > 0 else 0) for x in year_data[x_values].unique()]\n",
    "    return averages\n",
    "\n",
    "def plot_averages(grouped_data, label, x_values, x_label, title, file_suffix, xticks, xtick_labels):\n",
    "    averages = calculate_average(grouped_data, x_values)\n",
    "    \n",
    "    # Debugging output for calculated averages\n",
    "    print(f\"Calculated averages for {label}:\")\n",
    "    for year, values in averages.items():\n",
    "        print(f\"Year: {year}\")\n",
    "        for x, avg in values:\n",
    "            print(f\"  {x}: {avg}\")\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    for year, values in averages.items():\n",
    "        x_vals, avg_posts = zip(*values)\n",
    "        plt.plot(x_vals, avg_posts, 'o-', label=str(year))\n",
    "    plt.xticks(xticks, xtick_labels)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(f'Average Number of {label} per Channel')\n",
    "    plt.title(f'Average Number of {label} Per {title} (All Years)')\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'{visuals_folder}/all_years_{label}_{file_suffix}_average.jpg', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_usual(grouped_data, label, x_values, x_label, title, file_suffix, xticks, xtick_labels):\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    for year in grouped_data['year'].unique():\n",
    "        year_data = grouped_data[grouped_data['year'] == year]\n",
    "        plt.plot(year_data[x_values], year_data['number_of_posts'], 'o-', label=str(year))\n",
    "    plt.xticks(xticks, xtick_labels)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(f'Number of {label}')\n",
    "    plt.title(f'Number of {label} Per {title} (All Years)')\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'{visuals_folder}/all_years_{label}_{file_suffix}.jpg', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def perform_analysis(data, activity, label):\n",
    "    data = data.dropna(subset=[activity])\n",
    "    data['year'] = data['date'].dt.year\n",
    "    data['hour'] = data['date_unixtime']\n",
    "    data['day'] = pd.Categorical(data['date'].dt.day_name(), categories=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], ordered=True)\n",
    "    data['month'] = data['date'].dt.month\n",
    "\n",
    "    grouped_hourly = data.groupby(['year', 'hour']).agg(\n",
    "        number_of_posts=('date', 'size'),\n",
    "        number_of_active_channels=('file_name', 'nunique')\n",
    "    ).reset_index()\n",
    "\n",
    "    grouped_daily = data.groupby(['year', 'day']).agg(\n",
    "        number_of_posts=('date', 'size'),\n",
    "        number_of_active_channels=('file_name', 'nunique')\n",
    "    ).reset_index().sort_values(by=['year', 'day'])\n",
    "\n",
    "    grouped_monthly = data.groupby(['year', 'month']).agg(\n",
    "        number_of_posts=('date', 'size'),\n",
    "        number_of_active_channels=('file_name', 'nunique')\n",
    "    ).reset_index()\n",
    "\n",
    "    days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    month_names = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "    # Hourly analysis\n",
    "    plot_usual(grouped_hourly, label, 'hour', 'Hour of the Day', 'Hour', 'hourly', range(24), range(24))\n",
    "    plot_averages(grouped_hourly, label, 'hour', 'Hour of the Day', 'Hour', 'hourly', range(24), range(24))\n",
    "\n",
    "    # Daily analysis\n",
    "    plot_usual(grouped_daily, label, 'day', 'Day of the Week', 'Day of the Week', 'daily', range(len(days_of_week)), days_of_week)\n",
    "    plot_averages(grouped_daily, label, 'day', 'Day of the Week', 'Day of the Week', 'daily', range(len(days_of_week)), days_of_week)\n",
    "\n",
    "    # Monthly analysis\n",
    "    plot_usual(grouped_monthly, label, 'month', 'Month', 'Month', 'monthly', range(1, 13), month_names)\n",
    "    plot_averages(grouped_monthly, label, 'month', 'Month', 'Month', 'monthly', range(1, 13), month_names)\n",
    "\n",
    "def verify_averages(data, activity):\n",
    "    data = data.dropna(subset=[activity])\n",
    "    data['year'] = data['date'].dt.year\n",
    "    data['day'] = pd.Categorical(data['date'].dt.day_name(), categories=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], ordered=True)\n",
    "\n",
    "    grouped_daily = data.groupby(['year', 'day']).agg(\n",
    "        number_of_posts=('date', 'size'),\n",
    "        number_of_active_channels=('file_name', 'nunique')\n",
    "    ).reset_index().sort_values(by=['year', 'day'])\n",
    "\n",
    "    days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "    for year in grouped_daily['year'].unique():\n",
    "        print(f\"Year: {year}\")\n",
    "        year_data = grouped_daily[grouped_daily['year'] == year]\n",
    "        for day in days_of_week:\n",
    "            day_data = year_data[year_data['day'] == day]\n",
    "            num_posts = day_data['number_of_posts'].sum() if not day_data.empty else 0\n",
    "            num_active_channels = day_data['number_of_active_channels'].sum() if not day_data.empty else 0\n",
    "            avg_posts_per_channel = num_posts / num_active_channels if num_active_channels > 0 else 0\n",
    "            print(f\"Day: {day} - Number of {activity.capitalize()}s: {num_posts}, Number of Active Channels: {num_active_channels}, Average {activity.capitalize()}s per Channel: {avg_posts_per_channel}\")\n",
    "\n",
    "# Define the file lists\n",
    "file_list = ['new_online420fly_messages.xlsx', 'new_DalesSmokeshop_la_messages.xlsx', 'new_gollira_growers0_messages.xlsx', 'new_verified_members_la_official_messages.xlsx', 'new_jV0TiZVAMGA1MDVk_messages.xlsx', 'new_ghettomenu_messages.xlsx', 'new_vapesgmarket_messages.xlsx', 'new_vapeo_messages.xlsx', 'new_researchchemicalsconnect_messages.xlsx', 'new_Smokeplugla_messages.xlsx', 'new_TRIPPYSHIPPYDISTROMENU_messages.xlsx', 'new_Jokesupgeneticss_messages.xlsx', 'new_nycsmokeshop_messages.xlsx', 'new_thetrippyplug_messages.xlsx', 'new_Moonrocksmarket_messages.xlsx', 'new_k2spice_spray_sheets_paper_mamba_messages.xlsx', 'new_bubbafactoryla_messages.xlsx', 'new_MrTWilld_messages.xlsx', 'new_GAS_CARTEL_messages.xlsx', 'new_cbdoildestilate_messages.xlsx', 'new_WhitebluntzGumbohub_messages.xlsx', 'new_CaliPlugsMenu_messages.xlsx', 'new_smokeshoppingdelivery_messages.xlsx', 'new_weedsupplies1grower_messages.xlsx', 'new_deepmethod_messages.xlsx', 'new_narcosberlinnn_messages.xlsx', 'new_humboldtgrowersgroup_messages.xlsx', 'new_FuIlSendPackzz_messages.xlsx', 'new_laced917_messages.xlsx', 'new_Gasserybuds_messages.xlsx', 'new_trappedupp_messages.xlsx', 'new_allpacklandsla_messages.xlsx', 'new_trippyshore_messages.xlsx', 'new_BEST EXOTIC MARIJUANA 247_messages.xlsx', 'new_cali_distro_exotics_cali_plug_messages.xlsx', 'new_ssn_724365_messages.xlsx', 'new_thegunplug316_messages.xlsx', 'new_VLFlowerShopV2_messages.xlsx', 'new_Cracksnowflakeuk_messages.xlsx', 'new_Big Stoners Shop_messages.xlsx', 'new_smokeydistrol_messages.xlsx', 'new_smokeshopusa420_messages.xlsx', 'new_chatroomis_messages.xlsx', 'new_thesmokersclubuniverse_messages.xlsx', 'new_rodstraphouse_messages.xlsx', 'new_zushiwave_messages.xlsx', 'new_budiesjames_messages.xlsx', 'new_ganja420sho_messages.xlsx', 'new_whiteruntz_calikush_moonrocks_messages.xlsx', 'new_Exocticgashouse_messages.xlsx', 'new_smokeydistrola_messages.xlsx', 'new_vapingcultures_messages.xlsx', 'new_Swipe Life_messages.xlsx', 'new_gaspackstexas_messages.xlsx', 'new_Caliimport_messages.xlsx', 'new_californiagoldenshopdistro_messages.xlsx', 'new_astroexotics1_messages.xlsx', 'new_packmartlosangeIes_messages.xlsx', 'new_Vaping Culture_messages.xlsx', 'new_exotic_zaza247_messages.xlsx', 'new_trappy_exoctics_california_messages.xlsx', 'new_RubifenAdderallRitalin_messages.xlsx', 'new_traphouseexotics420_messages.xlsx', 'new_rappersfavtrapper_messages.xlsx', 'new_Trippyexoctic_messages.xlsx', 'new_zaza_carts_cookies_poundsclub_messages.xlsx', 'new_Hazydayz710_messages.xlsx', 'new_Trippysociet_messages.xlsx', 'new_drugzi_messages.xlsx', 'new_workspace2022_messages.xlsx', 'new_realpureperuviancocaine_messages.xlsx', 'new_Gasshouse070_messages.xlsx', 'new_caliplug695carte_messages.xlsx', 'new_Vaping RockNRoll_messages.xlsx', 'new_secretcannabis_messages.xlsx', 'new_kimmytantanvape_messages.xlsx', 'new_runtzog_official_messages.xlsx', 'new_flowerdistrctla_messages.xlsx', 'new_refertogetcompensated_messages.xlsx', 'new_Sherbmoney_Runtz_messages.xlsx', 'new_gascoexotics_shop_messages.xlsx', 'new_CCNumberGenerator_messages.xlsx', 'new_Buysellcannabinoidsk2spice_messages.xlsx', 'new_Mushrooms Ecstacy Pills_messages.xlsx', 'new_trappy_exotics_caliplug420_messages.xlsx', 'new_STPPromo_messages.xlsx', 'new_gasseryonly_messages.xlsx', 'new_distro_messages.xlsx', 'new_Loud_HouseExotics_messages.xlsx', 'new_texas_packs_plugs_messages.xlsx', 'new_RuntzOGcannag_messages.xlsx', 'new_Psychedelics Dispensary_messages.xlsx', 'new_trippyplugpromo_messages.xlsx', 'new_Exoticgenetix Mike_messages.xlsx', 'new_trappyexoticstouchdowns_messages.xlsx', 'new_michigangaspacks_messages.xlsx', 'new_trippyexoctic11_messages.xlsx', 'new_gasproshop302_messages.xlsx', 'new_never_soberTHC_messages.xlsx', 'new_safemedsusa_messages.xlsx', 'new_packmartmenu_messages.xlsx', 'new_trappy_exotics_caliplug_messages.xlsx', 'new_smokersclubla_messages.xlsx', 'new_Palmdale_Frisco8_messages.xlsx', 'new_sherbmoneyUS_messages.xlsx', 'new_smokeshopvendor_messages.xlsx', 'new_Trippypalacehome_messages.xlsx', 'new_MellowGodsflavors_messages.xlsx', 'new_trappyexoticsca_messages.xlsx', 'new_plugs_messages.xlsx', 'new_GassProShops_messages.xlsx', 'new_gasmartlaa_messages.xlsx']\n",
    "\n",
    "\n",
    "excluded_files = ['new_CCNumberGenerator_messages.xlsx', 'new_vapeo_messages.xlsx', 'new_Smokeplugla_messages.xlsx', \n",
    "                  'new_sherbmoneyUS_messages.xlsx', 'new_Palmdale_Frisco8_messages.xlsx', 'new_flowercitygaschat_messages.xlsx']\n",
    "excluded_years = [2016, 2017, 2018, 2019, 2024]\n",
    "\n",
    "# Load and concatenate all Excel files except the excluded ones\n",
    "data = load_and_concatenate_excel_files([file for file in file_list if file not in excluded_files])\n",
    "\n",
    "# Convert 'date' column to datetime\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Parse 'date_unixtime' to extract the hour\n",
    "data['date_unixtime'] = pd.to_datetime(data['date_unixtime'], format='%H:%M:%S').dt.hour\n",
    "\n",
    "# Exclude data from specified years\n",
    "data = data[~data['date'].dt.year.isin(excluded_years)]\n",
    "\n",
    "# Create a folder for saving visualizations\n",
    "visuals_folder = 'visuals_finale5'\n",
    "os.makedirs(visuals_folder, exist_ok=True)\n",
    "\n",
    "# Verify averages for photos\n",
    "verify_averages(data, 'photo')\n",
    "\n",
    "\n",
    "# Perform analysis for textual messages\n",
    "perform_analysis(data, 'text', 'Textual Messages')\n",
    "\n",
    "# Perform analysis for videos\n",
    "video_data = data[data['mime_type'] == 'video/mp4']\n",
    "perform_analysis(video_data, 'mime_type', 'Videos')\n",
    "\n",
    "# Perform analysis for photos\n",
    "perform_analysis(data, 'photo', 'Photos')\n",
    "\n",
    "# Perform analysis for total posts\n",
    "perform_analysis(data, 'date', 'Total Activity')\n",
    "\n",
    "print(\"Analysis complete and visualizations saved in 'visuals_finale1' folder\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
